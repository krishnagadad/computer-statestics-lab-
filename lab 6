# Program to perform cross-validation and calculate RMSE, MAE, and R2

from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.datasets import fetch_california_housing
import numpy as np
import warnings
warnings.filterwarnings("ignore", message="R^2 score is not well-defined*")

# --- Load dataset ---
X, y = fetch_california_housing(return_X_y=True)
model = LinearRegression()

# --- Validation Set Method ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=0)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Validation Set:")
print("RMSE =", np.sqrt(mean_squared_error(y_test, y_pred)))
print("MAE  =", mean_absolute_error(y_test, y_pred))
print("R2   =", r2_score(y_test, y_pred))

# --- Leave-One-Out Cross-Validation (LOOCV) ---
loo = LeaveOneOut()
rmse = np.sqrt(-cross_val_score(model, X, y, cv=loo, scoring='neg_mean_squared_error').mean())
mae = -cross_val_score(model, X, y, cv=loo, scoring='neg_mean_absolute_error').mean()
r2  = cross_val_score(model, X, y, cv=loo, scoring='r2').mean()
print("\nLOOCV:")
print("RMSE =", rmse)
print("MAE  =", mae)
print("R2   =", r2)

# --- K-Fold Cross-Validation ---
kfold = KFold(n_splits=5, shuffle=True, random_state=0)
rmse = np.sqrt(-cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error').mean())
mae = -cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_absolute_error').mean()
r2  = cross_val_score(model, X, y, cv=kfold, scoring='r2').mean()
print("\nK-Fold Cross-Validation:")
print("RMSE =", rmse)
print("MAE  =", mae)
print("R2   =", r2)
